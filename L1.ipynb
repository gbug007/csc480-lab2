{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8b-OpFXR1Nv"
      },
      "source": [
        "# CSC 480-F25 Lab 1: (Agentic) LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlvJxOkXQf0o"
      },
      "source": [
        "# Authors:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y0M9Wq5S2Wv"
      },
      "source": [
        "***Franz J. Kurfess, Siddarth Viswanathan, Charles O'Hanlon***\n",
        "\n",
        "California Polytechnic State University, San Luis Obispo;\n",
        "\n",
        "Computer Science & Software Engineering Department"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVI_bs4tQILD"
      },
      "source": [
        "# Part 1: Colab and Jupyter Notebooks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH-Fh3SkL5qR"
      },
      "outputs": [],
      "source": [
        "print(\"Hello World\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNFyUN2TV5xe"
      },
      "source": [
        "A Colab consists of a Jupyter notebook that is set up in the cloud. Jupyter notebooks (and thus Colabs) are composed of text cells (like this one) and code cells. An example of a code cell is below; it is marked by two square brackets '[ ]', which turn into an arrow when you move the cursor over them. Clicking on the arrow \"runs\" the cell: the code contained in the cell is executed. If the code produces an output, it is displayed underneath. There may be a number enclosed between the two brackets. This indicates that the code has been run multiple times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0TnSyf_pULA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYr9fSJuMA4y"
      },
      "source": [
        "## Google Account\n",
        "You need to have a Google account that lets you store files on GDrive. If you have a Gmail account, you should be able to go to [Google Drive](https://drive.google.com/) and log in with your Gmail login and password. If not, [set up a Google Account](https://support.google.com/accounts/answer/27441?hl=en) or reach out to your instructor about alternatives.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObEp5kafQTfp"
      },
      "source": [
        "## Create Your Copy\n",
        "If you want to use and modify a lab, you need to save a copy. To do so, go to the 'File' menu, select 'Save a copy in Drive' and change the name (it begins with 'Copy of ...'). You can share Colab notebooks with others, similar to sharing a document on Google Drive. Despite the possible interpretation of the name as \"Collaboration Lab\", collaborative editing of the same document is limited.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHL9QQl7QXW9"
      },
      "source": [
        "## Set Up a Colab\n",
        "Colabs run in the cloud through your Web browser. There's no need to install software on your computer. A Colab may require other software (libraries) to run, but this is done in the Colab itself, usually at the beginning.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm4rb6kITXQo"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1BYWB1QTeue"
      },
      "source": [
        "Let's apply our new knowledge of Jupyter Notebooks and work through some short coding exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRZebPe-UUYf"
      },
      "source": [
        "Identify the requirements and expectations concerning the background of the participants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysx6aVbsUiLk"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU2BOLDGUluv"
      },
      "source": [
        "*   Run and create code cells in a Jupyter Notebook\n",
        "*   Review function declaration and loops in Python\n",
        "* Explore external libraries like NumPy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNJ5iqyzsMIc"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG19Czm0sUuc"
      },
      "source": [
        "Given the array, `arr`, write a function that computes and prints the sum of each row or column.\n",
        "\n",
        "Input:\n",
        "\n",
        "*   `arr`, a 2-D array of integers\n",
        "*   `row_or_col`, an integer describing whether to calculate the sum over a row or column (0 = column, 1 = row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IT1EVpjsbkV"
      },
      "outputs": [],
      "source": [
        "arr = [[1, 4, 5, 6],\n",
        "       [5, 12, 3, 2],\n",
        "       [17, 34, 1, 0],\n",
        "       [4, 6, 7, 9]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdvhOW3JtjxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83a2f3a-b829-4c72-a46d-7e6f9988e2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "22\n",
            "52\n",
            "26\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "def sum_rows():\n",
        "  for arrs in arr:\n",
        "    sum = 0\n",
        "    for ar in arrs:\n",
        "      sum += ar\n",
        "    print(sum)\n",
        "\n",
        "sum_rows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XMbro9aHfjD"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpJ0BEDwuAIh"
      },
      "source": [
        "NumPy is a powerful Python library that can efficiently store high-dimensional lists. It also offers useful functions that can simplify list manipulation tasks or calculations (like the one above)\n",
        "\n",
        "Consult the [NumPy API](https://numpy.org/doc/stable/reference/index.html#reference) or use a Generative AI Tool to create a function that converts `arr` to a NumPy array and calculate the sum through a NumPy function call.\n",
        "(Converting the array can be done in a single line and calculating the sum can be done in a single line without writing a loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "msf3c-lHZ2NO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43b8cff-76d3-40a6-e4e9-27fec9c12111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy  # Install the numpy package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi8p9DlIwDqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4f9ea8-ab22-40e8-f4ec-b4225a71c61a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116\n"
          ]
        }
      ],
      "source": [
        "import numpy as np  # Normally all imports should be done at the top of a notebook\n",
        "\n",
        "# Write your code here\n",
        "def arr_to_numpy(array):\n",
        "  np_arr = np.array(array)\n",
        "\n",
        "  return np.sum(np_arr)\n",
        "\n",
        "print(arr_to_numpy(arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIl8T5cwZ2NO"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqpTUJ4gZ2NO"
      },
      "source": [
        "* Bonner, A. (2019). Getting Started With Google Colab. Medium.\n",
        "https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c\n",
        "* Dair.AI. (2019). Writing Primer for Data Scientists. DAIR Diverse Artificial Intelligence Research Initiative. https://colab.research.google.com/drive/1qi8bXjH389MipsFx3KVQQwGwefDgzzoe\n",
        "* Elvis. (2018). Primer for Learning Google Colab. Medium. https://medium.com/dair-ai/primer-for-learning-google-colab-bb4cabca5dd6\n",
        "* Google CoLab. (2018). Google Colaboratory: Welcome: Introduction to Machine Learning Labs. Google. https://colab.research.google.com/drive/1EIB6pAaMM6C2MIdxsrGntYrQoUfcsbmS#forceEdit=true&sandboxMode=true\n",
        "* Sagar, A. (2019). One-Stop Guide to Google Colab. Medium. https://towardsdatascience.com/one-stop-guide-to-google-colab-d67c94d30516\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQtcmEbf3e5e"
      },
      "source": [
        "# Part 2: AutoGen Framework and a Simple Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVKIrgEZ2NP"
      },
      "source": [
        "### Core Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AZpIytg593P7",
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe4817d-590c-46f7-edec-0226bef2446e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen-core\n",
            "  Downloading autogen_core-0.7.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting autogen-agentchat\n",
            "  Downloading autogen_agentchat-0.7.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting autogen-ext[azure,openai]\n",
            "  Downloading autogen_ext-0.7.5-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting jsonref~=1.1.0 (from autogen-core)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (1.37.0)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (11.3.0)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (2.11.9)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (4.15.0)\n",
            "Collecting azure-ai-inference>=1.0.0b9 (from autogen-ext[azure,openai])\n",
            "  Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting azure-ai-projects>=1.0.0b11 (from autogen-ext[azure,openai])\n",
            "  Downloading azure_ai_projects-1.1.0b4-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting azure-core (from autogen-ext[azure,openai])\n",
            "  Downloading azure_core-1.35.1-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-identity (from autogen-ext[azure,openai])\n",
            "  Downloading azure_identity-1.25.0-py3-none-any.whl.metadata (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-search-documents>=11.4.0 (from autogen-ext[azure,openai])\n",
            "  Downloading azure_search_documents-11.5.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from autogen-ext[azure,openai]) (24.1.0)\n",
            "Requirement already satisfied: openai>=1.93 in /usr/local/lib/python3.12/dist-packages (from autogen-ext[azure,openai]) (1.108.0)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from autogen-ext[azure,openai]) (0.11.0)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-inference>=1.0.0b9->autogen-ext[azure,openai])\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-storage-blob>=12.15.0 (from azure-ai-projects>=1.0.0b11->autogen-ext[azure,openai])\n",
            "  Downloading azure_storage_blob-12.26.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting azure-ai-agents>=1.2.0b3 (from azure-ai-projects>=1.0.0b11->autogen-ext[azure,openai])\n",
            "  Downloading azure_ai_agents-1.2.0b5-py3-none-any.whl.metadata (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from azure-core->autogen-ext[azure,openai]) (2.32.4)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from azure-core->autogen-ext[azure,openai]) (1.17.0)\n",
            "Collecting azure-common>=1.1 (from azure-search-documents>=11.4.0->autogen-ext[azure,openai])\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.34.1->autogen-core) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.8.0->autogen-ext[azure,openai]) (2024.11.6)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.12/dist-packages (from azure-identity->autogen-ext[azure,openai]) (43.0.3)\n",
            "Collecting msal>=1.30.0 (from azure-identity->autogen-ext[azure,openai])\n",
            "  Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->autogen-ext[azure,openai])\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.93->autogen-ext[azure,openai]) (3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=2.5->azure-identity->autogen-ext[azure,openai]) (2.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core) (3.23.0)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->autogen-ext[azure,openai]) (2.10.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core->autogen-ext[azure,openai]) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core->autogen-ext[azure,openai]) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->autogen-ext[azure,openai]) (2.23)\n",
            "Downloading autogen_core-0.7.5-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogen_agentchat-0.7.5-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_projects-1.1.0b4-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.35.1-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_search_documents-11.5.3-py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading autogen_ext-0.7.5-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.4/331.4 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.25.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_agents-1.2.0b5-py3-none-any.whl (217 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.9/217.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Downloading azure_storage_blob-12.26.0-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: azure-common, jsonref, isodate, azure-core, azure-storage-blob, azure-search-documents, azure-ai-inference, azure-ai-agents, autogen-core, msal, azure-ai-projects, autogen-ext, autogen-agentchat, msal-extensions, azure-identity\n",
            "Successfully installed autogen-agentchat-0.7.5 autogen-core-0.7.5 autogen-ext-0.7.5 azure-ai-agents-1.2.0b5 azure-ai-inference-1.0.0b9 azure-ai-projects-1.1.0b4 azure-common-1.1.28 azure-core-1.35.1 azure-identity-1.25.0 azure-search-documents-11.5.3 azure-storage-blob-12.26.0 isodate-0.7.2 jsonref-1.1.0 msal-1.34.0 msal-extensions-1.3.1\n"
          ]
        }
      ],
      "source": [
        "%pip install \"autogen-core\" \"autogen-agentchat\" \"autogen-ext[openai,azure]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Cp1zKFCtZ2NP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import asyncio\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.ui import Console\n",
        "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1F17K211Z2NP"
      },
      "outputs": [],
      "source": [
        "# For our Azure OpenAI deployment (wouldn't touch if I were you)\n",
        "azure_deployment = \"gpt-5-mini-lab1\"\n",
        "api_version = \"2024-12-01-preview\"  # If you're using gpt-5-mini as demonstrated\n",
        "\n",
        "# e.g. https://ccoha-mfoynknp-eastus2.cognitiveservices.azure.com/\n",
        "azure_endpoint = \"https://lab1agent-aifoundry.cognitiveservices.azure.com/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1-ck9QcZ2NP"
      },
      "source": [
        "## Simple Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "46SPZtdlZ2NP",
        "outputId": "72f76420-46b5-4039-c92d-1036c2eeda05"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3515034140.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Run the simple chat assistant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0msetup_simple_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3515034140.py\u001b[0m in \u001b[0;36msetup_simple_chat\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msetup_simple_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     client = AzureOpenAIChatCompletionClient(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mazure_deployment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mazure_deployment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-5-mini\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Only model we have deployed right now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mapi_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogen_ext/models/openai/_openai_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0minclude_name_in_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"include_name_in_message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_azure_openai_client_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0mcreate_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_args_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopied_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogen_ext/models/openai/_openai_client.py\u001b[0m in \u001b[0;36m_azure_openai_client_from_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAsyncAzureOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mazure_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/lib/azure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, azure_endpoint, azure_deployment, api_version, api_key, azure_ad_token, azure_ad_token_provider, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mazure_ad_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mazure_ad_token_provider\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;34m\"Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables."
          ]
        }
      ],
      "source": [
        "async def setup_simple_chat():\n",
        "    client = AzureOpenAIChatCompletionClient(\n",
        "        azure_deployment=azure_deployment,\n",
        "        model=\"gpt-5-mini\",  # Only model we have deployed right now\n",
        "        api_version=api_version,\n",
        "        azure_endpoint=azure_endpoint,\n",
        "        api_key=os.getenv(\"AZURE_SUBSCRIPTION_KEY\"),\n",
        "    )\n",
        "\n",
        "    assistant = AssistantAgent(\n",
        "        name=\"SimpleAgent\",\n",
        "        model_client=client,\n",
        "        # The system message guides the LLM's behavior. It's read by the model before each completion.\n",
        "        system_message=\"You are an approachable southern belle talking in a social setting. Provide witty responses but also be respectful of people's differences.\",\n",
        "    )\n",
        "\n",
        "    # Console function to print the response\n",
        "    await Console(assistant.run_stream(task=\"How do we solve the social and political division in the USA?\"))\n",
        "\n",
        "\n",
        "# Run the simple chat assistant\n",
        "await setup_simple_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvVfB75vZ2NP"
      },
      "source": [
        "Check out the AutoGen documentation [here](https://microsoft.github.io/autogen/stable/index.html) if you're interested in exploring the API further."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}